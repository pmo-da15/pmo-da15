from dataclasses import dataclass
from enum import Enum

from pydantic import BaseModel, TypeAdapter
from tqdm import tqdm

from src.misc import LineWindow, JSON_SCHEMA_URI, window_lines
from src.llms.adapter import LlmAdapter


class ExtractionRole(str, Enum):
    headline = "headline"
    subheadline = "subheadline"
    product_description = "product_description"
    cta = "cta"
    social_proof = "social_proof"
    key_section = "key_section"


class Fragment(BaseModel):
    role: ExtractionRole
    content: str


EXTRACTION_ROLES_FULL_NAMES = [
    (ExtractionRole.headline, "Main Headlines"),
    (ExtractionRole.subheadline, "Subheadlines"),
    (ExtractionRole.product_description, "Product Descriptions"),
    (ExtractionRole.cta, "CTA"),
    (ExtractionRole.social_proof, "Social Proofs"),
    (ExtractionRole.key_section, "Key Sections"),
]

EXTRACTION_INSTRUCT_PROMPT = f"""
You are a system for extracting marketing-relevant information from the homepage of a B2B website.
You receive fragments of raw markdown generated by crawl4ai. It may contain noise, duplicates, navigation items, UI elements, cookie banners, etc.

YOUR GOAL

Clean, normalize, and restructure the content so that only the elements relevant for evaluating a B2B homepage remain. As you receive only the fragments of input, the output will also be fragmented.

Your input will consist of 3 messages.
- The first message provides previous context for you: some lines BEFORE the main content. Content from this message MUST NOT be be included in output.
- The second message is the content message: its content MUST be included in your output.
- The third and last message provides subsequent context: some lines after the main content. Content from this message MUST NOT be be included in output.

The goal of this separation is to provide you with "sliding windows" of the input, as the full text is processed in chunks.

CLEANING RULES
Completely remove the following:
- Cookie banners, GDPR, privacy notices, legal terms, copyrights.
- Navigation noise: "Home", "Pricing", "Blog", "About", "Careers", dropdown menus, menu lists.
- Footer content: contacts, addresses, social links, repeated CTAs.
- UI/service elements: "Log in", "Sign up", "Menu", "Language", "Open app".
Duplicate blocks or repeated sentences.

EXTRACT AND KEEP ONLY THESE ELEMENTS
Structure the result as clean plain text (NO markdown!), split into clear sections:

- Main Headline (H1)
The primary message of the page. Extract the 1–2 strongest top-level headlines.

- Subheadline / Value Proposition
Short explanation of what the product does, for whom, and what problem it solves.

- Product Description
Meaningful paragraphs describing:
- features
- benefits
- pain points
- use cases
- core capabilities

CTAs (Calls to Action)
Examples: "Get a demo", "Start free trial", "Calculate ROI", "Contact sales.
Remove service buttons like "Log in".

Social Proof
- client logos (names only)
- testimonials
- case studies
- ROI metrics
- trusted numbers (e.g., "Used by 5,000 teams")

Key Marketing Sections
Extract titles and short content summaries of important functional sections such as:
- "How it works"
- "Why choose us"
- "Features"
- "Integrations"
- "Problem → Solution"
- "Benefits"

OUTPUT FORMAT
Your MUST output JSON (which will be enforced during sampling), which MUST follow this structure:

[
    {{
        "role": "<role>",
        "content": "<content>
    }},
    ...
],

Each fragment consists of:
- content: the cleaned (but otherwise unmodified) part of raw markdown.
- role: one of the following:
{"\n".join("  - " + name for _, name in EXTRACTION_ROLES_FULL_NAMES)}

ADDITIONAL RULES
Do NOT add anything that wasn't in the input.
Do NOT generalize or invent text; use original wording only.
Preserve meaning but fix broken structure.
NO markdown formatting at all.
"""

ExtractionOutput = TypeAdapter(list[Fragment])
EXTRACTION_OUTPUT_SCHEMA = ExtractionOutput.json_schema()


def compile_fragments(fragments: list[Fragment]) -> str:
    outputs = []

    for role, full_name in zip(ExtractionRole, EXTRACTION_ROLES_FULL_NAMES):
        matching = [f for f in fragments if f.role == role]
        texts = [f.content for f in matching]
        outputs.append("# " + full_name + "\n" + "\n".join(texts))

    return "\n\n".join(outputs)


async def extract_fragments_from_window(
    llm: LlmAdapter, win: LineWindow
) -> list[Fragment]:
    line_messages = [
        {"role": "user", "content": "\n".join(lines)}
        for lines in [win.previous, win.current, win.next]
    ]

    frags, _ = await llm.answer_json(
        [{"role": "system", "content": EXTRACTION_INSTRUCT_PROMPT}, *line_messages],
        EXTRACTION_OUTPUT_SCHEMA,
    )

    return [Fragment(f["role"], f["content"]) for f in frags]


async def extract_fragments_from_document(llm: LlmAdapter, doc: str) -> list[Fragment]:
    frags = []

    for win in tqdm(window_lines(doc, 10, 100)):
        frags += await extract_fragments_from_window(llm, win)

    return frags
